{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4643685-adfc-45d1-8163-044fb2b80c19",
   "metadata": {},
   "source": [
    "# Optimization log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6218c1db-7a38-42ca-a50b-6fac4dc8c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.benchmark import Compare, Fuzzer, FuzzedParameter, FuzzedTensor, ParameterAlias, Timer\n",
    "\n",
    "from torch_image_binarization.thresholding import su"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5041749-1131-4f5c-bb08-b6f877b50e1f",
   "metadata": {},
   "source": [
    "The algorithm is based on the NumPy implementation at https://github.com/nopperl/vectorized-image-binarization. In order to improve performance, the code was rewritten in Pytorch. Performance is enabled in two ways: first, GPU acceleration with CUDA. Secondly, the Pytorch code can be automatically converted into efficient Triton kernels using `torch.compile`. Since [`torch.compile` supports NumPy starting with version 2.1](https://pytorch.org/docs/stable/torch.compiler_faq.html#does-numpy-work-with-torch-compile), the NumPy-to-Pytorch conversion possibly could also be skipped. The latest Pytorch version (2.3) is used as earlier versions produced errors.\n",
    "\n",
    "Since the Otsu implementation of OpenCV used in the NumPy version of the algorithm is incompatible with Pytorch, a Pytorch version of Otsu's method is written. Initially, the [loop-based version of Otsu's method from OpenCV](https://docs.opencv.org/3.4/d7/d4d/tutorial_py_thresholding.html) was converted to Pytorch, but (expectedly) performed poorly (e.g., each iteration of the loop was converted into a Triton kernel). Therefore, a vector-based version inspired by [scikit-image](https://github.com/scikit-image/scikit-image/blob/v0.22.x/skimage/filters/thresholding.py#L312) was implemented in Pytorch.\n",
    "\n",
    "One easy performance improvement would be to perform calculations in bf16, but this lead to overflows due to the use of `torch.cumsum`.\n",
    "\n",
    "An integral part of Otsu's method is computing the image histogram. Unfortunately, the `torch.histogram` function is not supported by `torch.compile`. Therefore, a `histogram` function for grayscale images compatible with `torch.compile` was written.\n",
    "\n",
    "Together with the aforementioned changes, the code was improved to eliminate all graph breaks. Compiling the resulting singular graph with dynamic shapes leads to the Triton kernel in `compiled_kernel.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5245d809-3143-44ec-9c19-827cb2729d4f",
   "metadata": {},
   "source": [
    "## Benchmarks\n",
    "Now, benchmark the performance gains by using `torch.compile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c58f09-460e-4ce5-888f-5833905821ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f72b6239f10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed=123\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdeae945-117c-41d4-bcf3-c011a5b51cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(stmts, tensors_fixed=True, seed=seed):\n",
    "    if tensors_fixed:\n",
    "        tensor_generator = ((torch.rand(1, 2 ** i, 2 ** i, device=\"cuda\")) for i in range(8, 13))\n",
    "    else:\n",
    "        img_fuzzer = Fuzzer(\n",
    "            parameters = [\n",
    "                FuzzedParameter(\"h\", minval=256, maxval=8096, distribution='loguniform'),\n",
    "                FuzzedParameter(\"w\", minval=256, maxval=8096, distribution='loguniform'),\n",
    "            ],\n",
    "            tensors = [\n",
    "                FuzzedTensor(\"img\", size=(1, \"h\", \"w\"), probability_contiguous=1, cuda=True)\n",
    "            ],\n",
    "            seed=0,\n",
    "        )\n",
    "        tensor_generator = img_fuzzer.take(10)\n",
    "\n",
    "    measurements = []\n",
    "    for item in tensor_generator:\n",
    "        tensors = item[0]\n",
    "        for stmt in stmts:\n",
    "            measurement = Timer(\n",
    "                stmt=stmt,\n",
    "                setup=\"from __main__ import su\",\n",
    "                globals=tensors,\n",
    "                label=\"su\",\n",
    "                description=\"runtime\",\n",
    "            ).blocked_autorange(min_run_time=1)\n",
    "            measurements.append(measurement)\n",
    "    compare = Compare(measurements)\n",
    "    return compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73c8bf0-f4b9-4ae7-82f8-97399336b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmts = [\n",
    "    \"su(img)\",\n",
    "    \"torch.compile(su)(img)\",\n",
    "    \"torch.compile(su, mode='reduce-overhead')(img)\",\n",
    "    \"torch.compile(su, mode='max-autotune')(img)\",\n",
    "    \"torch.compile(su, dynamic=True)(img)\",\n",
    "    \"torch.compile(su, dynamic=True, mode='reduce-overhead')(img)\",\n",
    "    \"torch.compile(su, dynamic=True, mode='max-autotune')(img)\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba363c8-a731-46a0-9c8f-266c6790046b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------ su ------------------------------------]\n",
      "                                                                    |  runtime\n",
      "1 threads: -------------------------------------------------------------------\n",
      "      su(img)                                                       |  10426.5\n",
      "      torch.compile(su)(img)                                        |   1333.6\n",
      "      torch.compile(su, mode='reduce-overhead')(img)                |    858.8\n",
      "      torch.compile(su, mode='max-autotune')(img)                   |    859.6\n",
      "      torch.compile(su, dynamic=True)(img)                          |    859.7\n",
      "      torch.compile(su, dynamic=True, mode='reduce-overhead')(img)  |    860.0\n",
      "      torch.compile(su, dynamic=True, mode='max-autotune')(img)     |    860.0\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare = benchmark(stmts, tensors_fixed=False)\n",
    "compare.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d9c3b-af67-4372-bb70-3e5736ca42ef",
   "metadata": {},
   "source": [
    "The runtime measurements show that `torch.compile` enables a 12x speedup over the eager CUDA-based implementation. For reference, the CPU-based implementation takes roughly 3.5 seconds (= 3 548 992 us) on average, making the eager implementation approximately 340x and the `torch.compile` implementation 4125x faster.\n",
    "\n",
    "As expected, the `reduce-overhead` (CUDA graphs) and `max-autotune` (CUDA graphs + Triton autotune) modes lead to further performance gains over the default `torch.compile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05230923-70ed-4274-93f8-95932f61b591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
